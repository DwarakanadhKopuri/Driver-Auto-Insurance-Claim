{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "from scipy.stats import pointbiserialr\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "# Other\n",
    "from IPython.display import Image\n",
    "import configparser\n",
    "import gc # clear RAM\n",
    "import subprocess\n",
    "import warnings\n",
    "import pprint\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "0   7       0          2              2          5              1   \n",
       "1   9       0          1              1          7              0   \n",
       "2  13       0          5              4          9              1   \n",
       "3  16       0          0              1          2              0   \n",
       "4  17       0          0              2          0              1   \n",
       "\n",
       "   ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ...  \\\n",
       "0              0              0              1              0  ...   \n",
       "1              0              0              0              1  ...   \n",
       "2              0              0              0              1  ...   \n",
       "3              0              1              0              0  ...   \n",
       "4              0              1              0              0  ...   \n",
       "\n",
       "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0           9           1           5           8               0   \n",
       "1           3           1           1           9               0   \n",
       "2           4           2           7           7               0   \n",
       "3           2           2           4           9               0   \n",
       "4           3           1           1           3               0   \n",
       "\n",
       "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0               1               1               0               0   \n",
       "1               1               1               0               1   \n",
       "2               1               1               0               1   \n",
       "3               0               0               0               0   \n",
       "4               0               0               1               1   \n",
       "\n",
       "   ps_calc_20_bin  \n",
       "0               1  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Let's set working directory and import our data\n",
    "df = pd.read_csv('E:\\\\D_data\\\\Info\\\\A\\\\Nimmetry\\\\train.csv')\n",
    "### and test if everything OK # Getting top 5 observations in the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595212, 59)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No .of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Numerical features --- :  \n",
      " ['ps_ind_01', 'ps_ind_03', 'ps_ind_14', 'ps_ind_15', 'ps_reg_01', 'ps_reg_02', 'ps_reg_03', 'ps_car_11', 'ps_car_12', 'ps_car_13', 'ps_car_14', 'ps_car_15', 'ps_calc_01', 'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05', 'ps_calc_06', 'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10', 'ps_calc_11', 'ps_calc_12', 'ps_calc_13', 'ps_calc_14'] \n",
      "\n",
      "--- Categorical features --- :  \n",
      " ['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat', 'ps_car_05_cat', 'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat', 'ps_car_09_cat', 'ps_car_10_cat', 'ps_car_11_cat'] \n",
      "\n",
      "--- Binary features --- :  \n",
      " ['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_calc_15_bin', 'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin', 'ps_calc_19_bin', 'ps_calc_20_bin'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Seperating features\n",
    "#The dataset includes numerical, categorical and binary features. The numerical features consist of ordinal  and float values.\n",
    "#Each feature type needs to be treated separately, so first of all we can create three lists of columns for the three feature \n",
    "#types.separate col names into categories\n",
    "cols = df.columns\n",
    "num_feats, cat_feats, bin_feats = [], [], []\n",
    "\n",
    "for col in cols:\n",
    "    if col == 'id' or col == 'target':\n",
    "        pass\n",
    "    elif '_cat' in col:\n",
    "        cat_feats.append(col)\n",
    "    elif '_bin' in col:\n",
    "        bin_feats.append(col)\n",
    "    else:\n",
    "        num_feats.append(col)\n",
    "        \n",
    "print('--- Numerical features --- : ', '\\n', num_feats, '\\n')\n",
    "print('--- Categorical features --- : ', '\\n', cat_feats, '\\n')\n",
    "print('--- Binary features --- : ', '\\n', bin_feats, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of numeric features: 26\n",
      "No. of binary features: 17\n",
      "No. of Categorical features: 14\n"
     ]
    }
   ],
   "source": [
    "print ('No. of numeric features: %d'% len(num_feats))\n",
    "print ('No. of binary features: %d' % len(bin_feats))\n",
    "print ('No. of Categorical features: %d' % len(cat_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleansing\n",
    "#The next step is to check how many missing values there are for each feature type. \n",
    "#As a general rule, I like to eliminate features where more than one half of the values are missing.\n",
    "\n",
    "# Although it uses more memory, I prefer to create a new copy of the dataframe for each section\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "# I will also create copies for the feature lists\n",
    "num_feats_cleaned = num_feats.copy()\n",
    "cat_feats_cleaned = cat_feats.copy()\n",
    "bin_feats_cleaned = bin_feats.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#Numerical features\n",
    "#Let's check for missing values (-1) in the numerical feature columns.\n",
    "# I would like to eliminate any columns that consist of more than one half missing values (-1)\n",
    "num_many_missing = df_cleaned[num_feats_cleaned][df == -1].count() / len(df) > 0.50 # more than 50% missing values\n",
    "num_many_missing = num_many_missing.index[num_many_missing == True].tolist()\n",
    "print(num_many_missing)\n",
    "#No columns were returned. We can also have a look at exactly how many are missing in the applicable columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column   Missing count   Missing ratio\n",
      "ps_reg_03    107772    0.181\n",
      "ps_car_11    5    0.000\n",
      "ps_car_12    1    0.000\n",
      "ps_car_14    42620    0.072\n"
     ]
    }
   ],
   "source": [
    "counts = df_cleaned[num_feats_cleaned][df == -1].count()\n",
    "cols_with_missing = counts[counts.values > 0]\n",
    "print('Column  ', 'Missing count  ', 'Missing ratio')\n",
    "for col, count in zip(cols_with_missing.index, cols_with_missing.values):\n",
    "    print(col, '  ', count, '  ', '{:.3f}'.format(count / len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Conda\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "E:\\Conda\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can substitute the missing values with the applicable column mean. This will limit their impact on the results.\n",
    "# The few missing values that remain will be substituted with the column mean\n",
    "for col in num_feats_cleaned:\n",
    "    df_cleaned[col][df_cleaned[col] == -1] = df_cleaned[col].mean()\n",
    "# Check that no missing values remain\n",
    "(df_cleaned[num_feats_cleaned] == -1).sum().sum()   # sums instances of true for each column and then sums across columns\n",
    "\n",
    "#Hence , We can be satisfied that no missing values remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ps_car_03_cat']\n"
     ]
    }
   ],
   "source": [
    "#Categorical features\n",
    "#I would like to eliminate any columns that consist of more than one-half missing values (-1). \n",
    "#If features contain a relatively small proportion of missing values, these values can be converted to \n",
    "#dummy variables and may be a useful part of the analysis.\n",
    "cat_many_missing = df_cleaned[cat_feats_cleaned][df == -1].count() / len(df) > 0.5\n",
    "cat_many_missing = cat_many_missing.index[cat_many_missing == True].tolist()\n",
    "print(cat_many_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column   Missing count   Missing ratio\n",
      "ps_ind_02_cat    216    0.000\n",
      "ps_ind_04_cat    83    0.000\n",
      "ps_ind_05_cat    5809    0.010\n",
      "ps_car_01_cat    107    0.000\n",
      "ps_car_03_cat    411231    0.691\n",
      "ps_car_05_cat    266551    0.448\n",
      "ps_car_07_cat    11489    0.019\n",
      "ps_car_09_cat    569    0.001\n"
     ]
    }
   ],
   "source": [
    "# We can also have a look exactly how many are missing in the applicable columns\n",
    "counts = df_cleaned[cat_feats_cleaned][df == -1].count()\n",
    "cols_with_missing = counts[counts.values > 0]\n",
    "print('Column  ', 'Missing count  ', 'Missing ratio')\n",
    "for col, count in zip(cols_with_missing.index, cols_with_missing.values):\n",
    "    print(col, '  ', count, '  ', '{:.3f}'.format(count / len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I will remove the one column that I identified.\n",
    "df_cleaned.drop(columns=cat_many_missing, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cat_feats list needs to be updated\n",
    "for i in cat_many_missing: cat_feats_cleaned.remove(i)\n",
    "#Remaing missing values will be converted to dummy variables during the feature engineering stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#Binary features\n",
    "#Let's now check for missing values among the binary features.\n",
    "\n",
    "bin_many_missing = df_cleaned[bin_feats_cleaned][df == -1].count() / len(df) > 0.5\n",
    "bin_many_missing = bin_many_missing.index[bin_many_missing == True].tolist()\n",
    "print(bin_many_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can be sure that there are no features with more than half of there values missing. \n",
    "#Let's just make sure that no values at all are missing for the binary features.\n",
    "# Lets check for missing values, in case any exist\n",
    "counts = df_cleaned[bin_feats_cleaned][df == -1].count()\n",
    "cols_with_missing = counts[counts.values > 0]\n",
    "cols_with_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e80fd0d948>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Exploratory data analysis\n",
    "#In this section, I will first explore the correlation between numerical features and \n",
    "#then I will explore the correlation between each feature and the target variable.\n",
    "\n",
    "#Numerical features of float type\n",
    "\n",
    "# First of all, we only want to select float values\n",
    "df_float = df_cleaned.select_dtypes(['float64'])\n",
    "df_corr = df_float.corr().abs()\n",
    "# Setting a filter for values of 1 or less than 0.5\n",
    "filter = (df_corr == 1) | (df_corr < 0.5)\n",
    "# We can filter out values by setting them to 0\n",
    "df_corr[filter] = 0\n",
    "df_corr\n",
    "\n",
    "f, ax = plt.subplots(figsize=(15, 10))\n",
    "plt.title(\"\\nPearson correlation of numeric features\\n\", size=24)\n",
    "sns.heatmap(df_corr, annot=True, annot_kws={'size': 14},\n",
    "            cmap=sns.diverging_palette(220, 20, n=11))\n",
    "\n",
    "\n",
    "#We can see that there are strong correlations between four pairs of features.\n",
    "\n",
    "#Let's look at pair plots of the strongly correlated variables. \n",
    "#This way we can gain insight into the linear correlations between the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PS_CAR_11  | Correlation:  -0.0012200059764356686 | P-value:  0.3465855778814675\n",
      "PS_CALC_01  | Correlation:  0.0017819546519205688 | P-value:  0.1692009225762702\n",
      "PS_CALC_02  | Correlation:  0.0013596889783313768 | P-value:  0.29417898872429776\n",
      "PS_CALC_03  | Correlation:  0.0019069735964084597 | P-value:  0.14122944863624004\n",
      "PS_CALC_04  | Correlation:  3.2720455100513886e-05 | P-value:  0.9798605213204049\n",
      "PS_CALC_05  | Correlation:  0.0007708801365325178 | P-value:  0.5520221328272643\n",
      "PS_CALC_06  | Correlation:  8.182225978058816e-05 | P-value:  0.9496663862997508\n",
      "PS_CALC_07  | Correlation:  -0.00010347690485252616 | P-value:  0.9363706750415502\n",
      "PS_CALC_08  | Correlation:  -0.0010058548384190228 | P-value:  0.4377398857962218\n",
      "PS_CALC_09  | Correlation:  0.0007189675843641383 | P-value:  0.579111996896382\n",
      "PS_CALC_10  | Correlation:  0.001060834044478951 | P-value:  0.4131106666326748\n",
      "PS_CALC_11  | Correlation:  0.000371437394891013 | P-value:  0.7744467192571259\n",
      "PS_CALC_12  | Correlation:  -0.0011325853981359283 | P-value:  0.3822337726938518\n",
      "PS_CALC_13  | Correlation:  -0.0004464645318085574 | P-value:  0.7305104420166328\n",
      "PS_CALC_14  | Correlation:  0.0013622753431191705 | P-value:  0.2932615808570199\n"
     ]
    }
   ],
   "source": [
    "# check correlation between cols and target\n",
    "num_weak_corr = []\n",
    "for col in num_feats_cleaned:\n",
    "    corr, p = pointbiserialr(df_cleaned[col], df_cleaned['target'])\n",
    "    if p > .05:\n",
    "        print(col.upper(), ' | Correlation: ', corr, '| P-value: ', p)\n",
    "        num_weak_corr.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PS_CAR_10_CAT  | Chi2:  0.6489747744859562  | p-value:  0.7228978253269899\n"
     ]
    }
   ],
   "source": [
    "#Categorical features\n",
    "#For checking correlation between the categorical features and the target variable, we can create a crosstab table\n",
    "#using Pandas and apply the Chi-squared tool to determine a p-value. Once again, \n",
    "#if the p-value is more than 0.05, then we could reject that feature.\n",
    "\n",
    "cat_weak_corr = []\n",
    "for col in cat_feats_cleaned:\n",
    "    crosstab = pd.crosstab( df['target'], df_cleaned[col],  rownames = ['target'] , colnames =['feature'])\n",
    "    chi2, p, dof, ex = chi2_contingency(crosstab, correction=False)\n",
    "    if p > 0.05:\n",
    "        print(col.upper(), ' | Chi2: ', chi2, ' | p-value: ', p)\n",
    "        cat_weak_corr.append(col)\n",
    "#It appears that all but one of the categorical features are worth keeping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PS_IND_10_BIN  | Chi2:  1.4908391520731943  | p-value:  0.22208630630633355\n",
      "PS_IND_11_BIN  | Chi2:  2.192129807260059  | p-value:  0.13871738717830912\n",
      "PS_IND_13_BIN  | Chi2:  3.188775952779365  | p-value:  0.07414551103659972\n",
      "PS_CALC_15_BIN  | Chi2:  0.135285302884501  | p-value:  0.7130137900732124\n",
      "PS_CALC_16_BIN  | Chi2:  0.22479812854296694  | p-value:  0.6354080551735377\n",
      "PS_CALC_17_BIN  | Chi2:  0.015449567540015549  | p-value:  0.9010806852088695\n",
      "PS_CALC_18_BIN  | Chi2:  0.17519257769002702  | p-value:  0.6755376371151457\n",
      "PS_CALC_19_BIN  | Chi2:  1.7905405627285798  | p-value:  0.1808603146226591\n",
      "PS_CALC_20_BIN  | Chi2:  0.6685114869634994  | p-value:  0.413571052217771\n"
     ]
    }
   ],
   "source": [
    "#Binary features\n",
    "#We can do the same for the binary variables as we did for the categorical variables.\n",
    "bin_weak_corr = []\n",
    "for col in bin_feats_cleaned:\n",
    "    crosstab = pd.crosstab( df['target'], df_cleaned[col],  rownames = ['target'] , colnames =['feature'])\n",
    "    chi2, p, dof, ex = chi2_contingency(crosstab)\n",
    "    if p > 0.05:\n",
    "        print(col.upper(), ' | Chi2: ', chi2, ' | p-value: ', p)\n",
    "        bin_weak_corr.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- COMPLETE ---\n"
     ]
    }
   ],
   "source": [
    "#Using classification tools\n",
    "#Another approach is to use a classication tool - such as random forest - to determine the importance of each feature.\n",
    "#We can achieve this by fitting a model and then calling the feature_importances method.\n",
    "# Sets up a classifier and fits a model to all features of the dataset\n",
    "clf = RandomForestClassifier(n_estimators=150, max_depth=8, min_samples_leaf=4, max_features=0.2, n_jobs=-1, random_state=0)\n",
    "clf.fit(df_cleaned.drop(['id', 'target'],axis=1), df_cleaned['target'])\n",
    "# We need a list of features as well\n",
    "features = df_cleaned.drop(['id', 'target'],axis=1).columns.values\n",
    "print(\"--- COMPLETE ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clf_model.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, 'clf_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "marker": {
          "color": [
           0.0004103841098142345,
           0.0006106860367380346,
           0.0009150539343833182,
           0.001207482177366205,
           0.0013460631152604036,
           0.0017826629632753798,
           0.00198861101967581,
           0.0022300683149961377,
           0.002233708902779629,
           0.002334136671310185,
           0.0023895562973426797,
           0.002474218227498505,
           0.0024902221111195305,
           0.003965336318280382,
           0.004593581450746388,
           0.004731938417326481,
           0.006908613326149673,
           0.007895833601363964,
           0.008113718360158098,
           0.008684059902365282,
           0.00908463996951658,
           0.009258099279449105,
           0.009487899915921227,
           0.010449328157024413,
           0.010701116541925317,
           0.010828867449049576,
           0.011370980349247908,
           0.011618205210900954,
           0.011893215283430531,
           0.012006358062937714,
           0.012096756254500617,
           0.013986149235899935,
           0.014095019379364334,
           0.014594097319926148,
           0.0155444574347585,
           0.01569230358768901,
           0.01647449015051489,
           0.017004242173101362,
           0.017140261645788708,
           0.018001347113009044,
           0.018310828041094917,
           0.01881921611035361,
           0.018992794776938837,
           0.022537754820251884,
           0.025684911534433655,
           0.02618539878898033,
           0.026268435655700268,
           0.02958316087023743,
           0.029584035648845645,
           0.03478523266666995,
           0.038297299857715336,
           0.04050054426427717,
           0.05752432238348098,
           0.0754584750251459,
           0.07915580048493567,
           0.12967801929903222
          ],
          "reversescale": true
         },
         "name": "Random Forest Feature importance",
         "orientation": "h",
         "type": "bar",
         "x": [
          0.0004103841098142345,
          0.0006106860367380346,
          0.0009150539343833182,
          0.001207482177366205,
          0.0013460631152604036,
          0.0017826629632753798,
          0.00198861101967581,
          0.0022300683149961377,
          0.002233708902779629,
          0.002334136671310185,
          0.0023895562973426797,
          0.002474218227498505,
          0.0024902221111195305,
          0.003965336318280382,
          0.004593581450746388,
          0.004731938417326481,
          0.006908613326149673,
          0.007895833601363964,
          0.008113718360158098,
          0.008684059902365282,
          0.00908463996951658,
          0.009258099279449105,
          0.009487899915921227,
          0.010449328157024413,
          0.010701116541925317,
          0.010828867449049576,
          0.011370980349247908,
          0.011618205210900954,
          0.011893215283430531,
          0.012006358062937714,
          0.012096756254500617,
          0.013986149235899935,
          0.014095019379364334,
          0.014594097319926148,
          0.0155444574347585,
          0.01569230358768901,
          0.01647449015051489,
          0.017004242173101362,
          0.017140261645788708,
          0.018001347113009044,
          0.018310828041094917,
          0.01881921611035361,
          0.018992794776938837,
          0.022537754820251884,
          0.025684911534433655,
          0.02618539878898033,
          0.026268435655700268,
          0.02958316087023743,
          0.029584035648845645,
          0.03478523266666995,
          0.038297299857715336,
          0.04050054426427717,
          0.05752432238348098,
          0.0754584750251459,
          0.07915580048493567,
          0.12967801929903222
         ],
         "y": [
          "ps_ind_10_bin",
          "ps_ind_13_bin",
          "ps_ind_11_bin",
          "ps_ind_12_bin",
          "ps_calc_15_bin",
          "ps_calc_20_bin",
          "ps_ind_18_bin",
          "ps_calc_18_bin",
          "ps_car_10_cat",
          "ps_calc_16_bin",
          "ps_ind_14",
          "ps_calc_19_bin",
          "ps_calc_17_bin",
          "ps_ind_09_bin",
          "ps_car_08_cat",
          "ps_ind_08_bin",
          "ps_car_11",
          "ps_calc_04",
          "ps_car_05_cat",
          "ps_calc_09",
          "ps_car_09_cat",
          "ps_calc_06",
          "ps_calc_12",
          "ps_car_02_cat",
          "ps_calc_05",
          "ps_calc_07",
          "ps_calc_08",
          "ps_calc_02",
          "ps_calc_13",
          "ps_calc_01",
          "ps_calc_03",
          "ps_ind_02_cat",
          "ps_car_11_cat",
          "ps_car_06_cat",
          "ps_reg_01",
          "ps_ind_16_bin",
          "ps_calc_14",
          "ps_calc_11",
          "ps_ind_01",
          "ps_calc_10",
          "ps_ind_04_cat",
          "ps_ind_06_bin",
          "ps_car_15",
          "ps_ind_07_bin",
          "ps_car_12",
          "ps_ind_15",
          "ps_car_01_cat",
          "ps_car_14",
          "ps_car_04_cat",
          "ps_car_07_cat",
          "ps_ind_03",
          "ps_reg_02",
          "ps_ind_17_bin",
          "ps_reg_03",
          "ps_ind_05_cat",
          "ps_car_13"
         ]
        }
       ],
       "layout": {
        "height": 1500,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Ranking of most influential features"
        },
        "width": 900,
        "yaxis": {
         "showgrid": false,
         "showline": false,
         "showticklabels": true
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"6e989614-2d41-49a9-bb83-4b002dd4ce2f\" class=\"plotly-graph-div\" style=\"height:1500px; width:900px;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"6e989614-2d41-49a9-bb83-4b002dd4ce2f\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '6e989614-2d41-49a9-bb83-4b002dd4ce2f',\n",
       "                        [{\"marker\": {\"color\": [0.0004103841098142345, 0.0006106860367380346, 0.0009150539343833182, 0.001207482177366205, 0.0013460631152604036, 0.0017826629632753798, 0.00198861101967581, 0.0022300683149961377, 0.002233708902779629, 0.002334136671310185, 0.0023895562973426797, 0.002474218227498505, 0.0024902221111195305, 0.003965336318280382, 0.004593581450746388, 0.004731938417326481, 0.006908613326149673, 0.007895833601363964, 0.008113718360158098, 0.008684059902365282, 0.00908463996951658, 0.009258099279449105, 0.009487899915921227, 0.010449328157024413, 0.010701116541925317, 0.010828867449049576, 0.011370980349247908, 0.011618205210900954, 0.011893215283430531, 0.012006358062937714, 0.012096756254500617, 0.013986149235899935, 0.014095019379364334, 0.014594097319926148, 0.0155444574347585, 0.01569230358768901, 0.01647449015051489, 0.017004242173101362, 0.017140261645788708, 0.018001347113009044, 0.018310828041094917, 0.01881921611035361, 0.018992794776938837, 0.022537754820251884, 0.025684911534433655, 0.02618539878898033, 0.026268435655700268, 0.02958316087023743, 0.029584035648845645, 0.03478523266666995, 0.038297299857715336, 0.04050054426427717, 0.05752432238348098, 0.0754584750251459, 0.07915580048493567, 0.12967801929903222], \"reversescale\": true}, \"name\": \"Random Forest Feature importance\", \"orientation\": \"h\", \"type\": \"bar\", \"x\": [0.0004103841098142345, 0.0006106860367380346, 0.0009150539343833182, 0.001207482177366205, 0.0013460631152604036, 0.0017826629632753798, 0.00198861101967581, 0.0022300683149961377, 0.002233708902779629, 0.002334136671310185, 0.0023895562973426797, 0.002474218227498505, 0.0024902221111195305, 0.003965336318280382, 0.004593581450746388, 0.004731938417326481, 0.006908613326149673, 0.007895833601363964, 0.008113718360158098, 0.008684059902365282, 0.00908463996951658, 0.009258099279449105, 0.009487899915921227, 0.010449328157024413, 0.010701116541925317, 0.010828867449049576, 0.011370980349247908, 0.011618205210900954, 0.011893215283430531, 0.012006358062937714, 0.012096756254500617, 0.013986149235899935, 0.014095019379364334, 0.014594097319926148, 0.0155444574347585, 0.01569230358768901, 0.01647449015051489, 0.017004242173101362, 0.017140261645788708, 0.018001347113009044, 0.018310828041094917, 0.01881921611035361, 0.018992794776938837, 0.022537754820251884, 0.025684911534433655, 0.02618539878898033, 0.026268435655700268, 0.02958316087023743, 0.029584035648845645, 0.03478523266666995, 0.038297299857715336, 0.04050054426427717, 0.05752432238348098, 0.0754584750251459, 0.07915580048493567, 0.12967801929903222], \"y\": [\"ps_ind_10_bin\", \"ps_ind_13_bin\", \"ps_ind_11_bin\", \"ps_ind_12_bin\", \"ps_calc_15_bin\", \"ps_calc_20_bin\", \"ps_ind_18_bin\", \"ps_calc_18_bin\", \"ps_car_10_cat\", \"ps_calc_16_bin\", \"ps_ind_14\", \"ps_calc_19_bin\", \"ps_calc_17_bin\", \"ps_ind_09_bin\", \"ps_car_08_cat\", \"ps_ind_08_bin\", \"ps_car_11\", \"ps_calc_04\", \"ps_car_05_cat\", \"ps_calc_09\", \"ps_car_09_cat\", \"ps_calc_06\", \"ps_calc_12\", \"ps_car_02_cat\", \"ps_calc_05\", \"ps_calc_07\", \"ps_calc_08\", \"ps_calc_02\", \"ps_calc_13\", \"ps_calc_01\", \"ps_calc_03\", \"ps_ind_02_cat\", \"ps_car_11_cat\", \"ps_car_06_cat\", \"ps_reg_01\", \"ps_ind_16_bin\", \"ps_calc_14\", \"ps_calc_11\", \"ps_ind_01\", \"ps_calc_10\", \"ps_ind_04_cat\", \"ps_ind_06_bin\", \"ps_car_15\", \"ps_ind_07_bin\", \"ps_car_12\", \"ps_ind_15\", \"ps_car_01_cat\", \"ps_car_14\", \"ps_car_04_cat\", \"ps_car_07_cat\", \"ps_ind_03\", \"ps_reg_02\", \"ps_ind_17_bin\", \"ps_reg_03\", \"ps_ind_05_cat\", \"ps_car_13\"]}],\n",
       "                        {\"height\": 1500, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Ranking of most influential features\"}, \"width\": 900, \"yaxis\": {\"showgrid\": false, \"showline\": false, \"showticklabels\": true}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('6e989614-2d41-49a9-bb83-4b002dd4ce2f');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Knowing feature importance indicated by machine learning models can benefit you in multiple ways, for example:\n",
    "#by getting a better understanding of the modelâ€™s logic you can not only verify it being correct but also work on\n",
    "#improving the model by focusing only on the important variables the above can be used for variable selection \n",
    "#you can remove x variables that are not that significant and have similar or better performance in much shorter training time\n",
    "#in some business cases it makes sense to sacrifice some accuracy for the sake of interpretability\n",
    "\n",
    "x, y = (list(x) for x in zip(*sorted(zip(clf.feature_importances_, features), \n",
    "                                                            reverse = False)))\n",
    "trace2 = go.Bar(\n",
    "    x=x ,\n",
    "    y=y,\n",
    "    marker=dict(\n",
    "        color=x,\n",
    "        colorscale = None,\n",
    "        reversescale = True\n",
    "    ),\n",
    "    name='Random Forest Feature importance',\n",
    "    orientation='h',\n",
    ")\n",
    "\n",
    "layout = dict(\n",
    "    title='Ranking of most influential features',\n",
    "     width = 900, height = 1500,\n",
    "    yaxis=dict(\n",
    "        showgrid=False,\n",
    "        showline=False,\n",
    "        showticklabels=True,\n",
    "    ))\n",
    "\n",
    "fig1 = go.Figure(data=[trace2])\n",
    "fig1['layout'].update(layout)\n",
    "py.iplot(fig1, filename='plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature selection\n",
    "#I would like to select only the features that have the greatest impact according to the graph above,\n",
    "#with a combination of all features types.\n",
    "feats_to_keep = ['ps_ind_06_bin',\n",
    "                     'ps_car_15',\n",
    "                     'ps_ind_07_bin',\n",
    "                     'ps_car_12',\n",
    "                     'ps_car_01_cat',\n",
    "                     'ps_ind_15',\n",
    "                     'ps_car_14',\n",
    "                     'ps_car_04_cat',\n",
    "                     'ps_car_07_cat',\n",
    "                     'ps_ind_03',\n",
    "                     'ps_reg_02',\n",
    "                     'ps_ind_17_bin',\n",
    "                     'ps_reg_03',\n",
    "                     'ps_ind_05_cat',\n",
    "                     'ps_car_13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Numerical features --- :  \n",
      " ['ps_car_15', 'ps_car_12', 'ps_ind_15', 'ps_car_14', 'ps_ind_03', 'ps_reg_02', 'ps_reg_03', 'ps_car_13'] \n",
      "\n",
      "--- Categorical features --- :  \n",
      " ['ps_car_01_cat', 'ps_car_04_cat', 'ps_car_07_cat', 'ps_ind_05_cat'] \n",
      "\n",
      "--- Binary features --- :  \n",
      " ['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_17_bin'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create new dataframe with only selected features, target and id\n",
    "df_select_feats = df_cleaned[['id', 'target'] + feats_to_keep]\n",
    "\n",
    "# separate col names into categories\n",
    "num_feats_to_keep, cat_feats_to_keep, bin_feats_to_keep = [], [], []\n",
    "\n",
    "for col in feats_to_keep:\n",
    "    if col == 'id' or col == 'target':\n",
    "        pass\n",
    "    elif '_cat' in col:\n",
    "        cat_feats_to_keep.append(col)\n",
    "    elif '_bin' in col:\n",
    "        bin_feats_to_keep.append(col)\n",
    "    else:\n",
    "        num_feats_to_keep.append(col)\n",
    "        \n",
    "print('--- Numerical features --- : ', '\\n', num_feats_to_keep, '\\n')\n",
    "print('--- Categorical features --- : ', '\\n', cat_feats_to_keep, '\\n')\n",
    "print('--- Binary features --- : ', '\\n', bin_feats_to_keep, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineering\n",
    "#We still need to deal with the categorical variables because they cannot read in as they are. We need to create dummy variables\n",
    "#for each feature. This will greatly increase the number of features that we have,so I would like to minimize these features \n",
    "#if I can.\n",
    "df_engineered = df_select_feats.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ps_car_01_cat    13\n",
       "ps_car_04_cat    10\n",
       "ps_car_07_cat     3\n",
       "ps_ind_05_cat     8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can check how many categories there are for each feature. This way we know which features are going to result in \n",
    "#the most additional features after converting them to dummy variables.\n",
    "df_engineered[cat_feats_to_keep].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert cat feats to dummy variables (0s and 1s)\n",
    "cat_dummy_df = pd.get_dummies(df_engineered[cat_feats_to_keep].astype(str))\n",
    "# replacing original cat cols with new dummie cols\n",
    "df_engineered = pd.concat([df_engineered, cat_dummy_df], axis=1).drop(columns=cat_feats_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595212, 47)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_engineered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    573518\n",
       "1     21694\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Class balancing\n",
    "#1. There is very high imbalance which is evident of the fact that only a small number of people actually file their claim.\n",
    "#2. Accuracy is not a good metric in this case.Recall and F1-Score is a better option.\n",
    "#Before going into feature scaling, I would like to check out the ratio of ones to zeros in the target variable. \n",
    "#The reason I want to do this is because I already know that there is a very large class imbalance.\n",
    "#We would not expect half of the people who are insured to lodge a claim.\n",
    "\n",
    "df_engineered['target'].value_counts()\n",
    "\n",
    "#Sure enough, there are many more zeros. We can either over-sample (duplicate the training examples corresponding to the ones)\n",
    "#or under-sample (remove training examples corresponding to the zeros)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of ones to zeros:  3.7826188541597645  %\n"
     ]
    }
   ],
   "source": [
    "# number of zeros\n",
    "num_zeros = (df_engineered['target'] == 0).sum()\n",
    "# number of ones\n",
    "num_ones = (df_engineered['target'] == 1).sum()\n",
    "# difference in the number of zeros and ones\n",
    "diff = num_zeros - num_ones\n",
    "# ratios\n",
    "ones_to_zeros = num_ones / num_zeros\n",
    "zeros_to_ones = num_zeros / num_ones\n",
    "print('Ratio of ones to zeros: ', ones_to_zeros * 100, ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = len(df)\n",
    "#Sampling from examples with a target of zero\n",
    "#I would like to select a sample that makes up half of the original length of the dataset.\n",
    "df_zeros = df_engineered[df_engineered['target'] == 0]\n",
    "df_zeros_sample = df_zeros.sample(n=int(rows / 2), random_state=42)\n",
    "df_zeros_sample.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_car_15</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_car_12</th>\n",
       "      <th>ps_ind_15</th>\n",
       "      <th>ps_car_14</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_reg_02</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_car_07_cat_0</th>\n",
       "      <th>ps_car_07_cat_1</th>\n",
       "      <th>ps_ind_05_cat_-1</th>\n",
       "      <th>ps_ind_05_cat_0</th>\n",
       "      <th>ps_ind_05_cat_1</th>\n",
       "      <th>ps_ind_05_cat_2</th>\n",
       "      <th>ps_ind_05_cat_3</th>\n",
       "      <th>ps_ind_05_cat_4</th>\n",
       "      <th>ps_ind_05_cat_5</th>\n",
       "      <th>ps_ind_05_cat_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>465947</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.624980</td>\n",
       "      <td>5</td>\n",
       "      <td>0.422493</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>381915</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.741657</td>\n",
       "      <td>0</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>6</td>\n",
       "      <td>0.288791</td>\n",
       "      <td>9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1060494</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.407431</td>\n",
       "      <td>7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>469383</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.374166</td>\n",
       "      <td>13</td>\n",
       "      <td>0.382099</td>\n",
       "      <td>8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>491496</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.741657</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.309677</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  target  ps_ind_06_bin  ps_car_15  ps_ind_07_bin  ps_car_12  \\\n",
       "0   465947       0              1   0.000000              0   0.624980   \n",
       "1   381915       0              0   3.741657              0   0.316228   \n",
       "2  1060494       0              1   3.464102              0   0.400000   \n",
       "3   469383       0              0   3.000000              1   0.374166   \n",
       "4   491496       0              1   3.741657              0   0.400000   \n",
       "\n",
       "   ps_ind_15  ps_car_14  ps_ind_03  ps_reg_02  ...  ps_car_07_cat_0  \\\n",
       "0          5   0.422493          3        0.2  ...                0   \n",
       "1          6   0.288791          9        0.5  ...                0   \n",
       "2          8   0.407431          7        0.8  ...                0   \n",
       "3         13   0.382099          8        0.4  ...                0   \n",
       "4         12   0.309677          2        0.2  ...                0   \n",
       "\n",
       "   ps_car_07_cat_1  ps_ind_05_cat_-1  ps_ind_05_cat_0  ps_ind_05_cat_1  \\\n",
       "0                1                 0                1                0   \n",
       "1                1                 0                1                0   \n",
       "2                1                 0                1                0   \n",
       "3                1                 0                1                0   \n",
       "4                1                 0                1                0   \n",
       "\n",
       "   ps_ind_05_cat_2  ps_ind_05_cat_3  ps_ind_05_cat_4  ps_ind_05_cat_5  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   ps_ind_05_cat_6  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zeros_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Duplicating examples with a target of one\n",
    "#I will duplicate all of the examples corresponding to ones.\n",
    "df_ones = df_engineered[df_engineered['target'] == 1]\n",
    "# Adds duplicates of the ones set until half of the dataset is occupied\n",
    "df_ones_dup = pd.DataFrame()\n",
    "for i in range(int((rows / 2) / num_ones)):\n",
    "    df_ones_dup = df_ones_dup.append(df_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining examples into one dataset\n",
    "df_rebalanced = pd.concat([df_zeros_sample, df_ones_dup])\n",
    "df_rebalanced = df_rebalanced.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579628, 47)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rebalanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The number of rows is similar to what we started with.\n",
    "\n",
    "#Feature scaling\n",
    "#Scaling features tends to lead to a performance improvement with classification problems, so we will do it here.\n",
    "\n",
    "df_scaled = df_rebalanced.copy()\n",
    "df_scaled.drop(columns=['target', 'id'], inplace=True)\n",
    "# Set up scaler and create a scaled input matrix\n",
    "scaler = MinMaxScaler()\n",
    "# MinMaxScalar outputs data as a numpy array (which is necessary for XGBoost)\n",
    "X_scaled = scaler.fit_transform(df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.The Simple Logistic Regression Model seems to have high accuracy. Is that what we need at all? What is the problem with this model? \n",
    "\n",
    "Here , we have a scenario where the number of observations belonging to one class is significantly lower than those belonging to the other classes ( 0 and 1) Which we call it as Im_balanced target variable . \n",
    "\n",
    "So , it involves first using a classification model to make a prediction for each example in a test dataset. The predictions are then compared to the known labels for those examples in the test set. Accuracy is then calculated as the proportion of examples in the test set that were predicted correctly, divided by all predictions that were made on the test set.\n",
    "\n",
    "#Accuracy = Correct Predictions / Total Predictions\n",
    "\n",
    "So , Classification accuracy fails on classification problems with a skewed class distribution because of the intuitions developed by practitioners on datasets with an equal class distribution.\n",
    "\n",
    "No , im my model building i have XGBOOST and MLP Classifier performed better than Logistic regression.\n",
    "\n",
    "F1-score: This is the harmonic mean of Precision and Recall and gives a better measure of the incorrectly classified cases than the Accuracy Metric.\n",
    "\n",
    "\n",
    "# 2. Why do you think f1-score is 0.0? \n",
    "No , here F1-Score is not 0. Yes , it becomes zero \n",
    "\n",
    "F1_Score:\n",
    "\n",
    "As The F1 score is the harmonic mean of precision and recall taking both metrics into account in the following equation:\n",
    "\n",
    "We use the harmonic mean instead of a simple average because it punishes extreme values. A classifier with a precision of 1.0 and a recall of 0.0 has a simple average of 0.5 but an F1 score of 0. The F1 score gives equal weight to both measures and is a specific example of the general metric which can be adjusted to give more weight to either recall or precision. (There are other metrics for combining precision and recall, such as the Geometric Mean of precision and recall, but the F1 score is the most commonly used.) If we want to create a balanced classification model with the optimal balance of recall and precision, then we try to maximize the F1 score.\n",
    "\n",
    "# 3.What is the precision and recall score for the model? \n",
    "Precision quantifies the number of positive class predictions that actually belong to the positive class. Recall quantifies the number of positive class predictions made out of all positive examples in the dataset.\n",
    "\n",
    "For Logistic Regression Precison and Recall Score are in the below matrix output .\n",
    "\n",
    "#The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal. The formula for the F1 score is:\n",
    "\n",
    "#F1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosen Models:\n",
    "#Logistic Regression is used when the dependent variable(target) is categorical.\n",
    "#XGBoost : learning_ratefloat, default=0.1 learning rate shrinks the contribution of each tree by learning_rate. \n",
    "#There is a trade-off between learning_rate and n_estimators.\n",
    "\n",
    "n_estimatorsint, default=100\n",
    "\n",
    "#The number of boosting stages to perform. Gradient boosting is fairly robust to over-fitting so a large number usually \n",
    "#results in better performance\n",
    "\n",
    "max_depthint, default=3\n",
    "\n",
    "#maximum depth of the individual regression estimators. The maximum depth limits the number of nodes in the tree. \n",
    "#Tune this parameter for best performance; the best value depends on the interaction of the input variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "++++++++++++++ LogReg ++++++++++++++\n",
      "\n",
      "\n",
      "--- Training model using LogReg ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Conda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DONE ===\n",
      "\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.67      0.63     59421\n",
      "           1       0.59      0.50      0.54     56505\n",
      "\n",
      "    accuracy                           0.59    115926\n",
      "   macro avg       0.59      0.59      0.58    115926\n",
      "weighted avg       0.59      0.59      0.59    115926\n",
      " \n",
      "\n",
      "\n",
      "++++++++++++++ XGBoost ++++++++++++++\n",
      "\n",
      "\n",
      "--- Training model using XGBoost ---\n",
      "=== DONE ===\n",
      "\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.68      0.65     59421\n",
      "           1       0.62      0.54      0.58     56505\n",
      "\n",
      "    accuracy                           0.62    115926\n",
      "   macro avg       0.62      0.61      0.61    115926\n",
      "weighted avg       0.62      0.62      0.61    115926\n",
      " \n",
      "\n",
      "\n",
      "++++++++++++++ LinearSVC ++++++++++++++\n",
      "\n",
      "\n",
      "--- Training model using LinearSVC ---\n",
      "=== DONE ===\n",
      "\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.68      0.63     59421\n",
      "           1       0.59      0.50      0.54     56505\n",
      "\n",
      "    accuracy                           0.59    115926\n",
      "   macro avg       0.59      0.59      0.58    115926\n",
      "weighted avg       0.59      0.59      0.59    115926\n",
      " \n",
      "\n",
      "\n",
      "++++++++++++++ MLPClassifier ++++++++++++++\n",
      "\n",
      "\n",
      "--- Training model using MLPClassifier ---\n",
      "=== DONE ===\n",
      "\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.68      0.64     59421\n",
      "           1       0.61      0.52      0.56     56505\n",
      "\n",
      "    accuracy                           0.60    115926\n",
      "   macro avg       0.60      0.60      0.60    115926\n",
      "weighted avg       0.60      0.60      0.60    115926\n",
      " \n",
      "\n",
      "\n",
      "++++++++++++++ AdaBoost ++++++++++++++\n",
      "\n",
      "\n",
      "--- Training model using AdaBoost ---\n",
      "=== DONE ===\n",
      "\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.66      0.63     59421\n",
      "           1       0.60      0.52      0.56     56505\n",
      "\n",
      "    accuracy                           0.59    115926\n",
      "   macro avg       0.59      0.59      0.59    115926\n",
      "weighted avg       0.59      0.59      0.59    115926\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = X_scaled\n",
    "# y needs to be converted to an array\n",
    "y = df_rebalanced['target'].to_numpy()\n",
    "# split up the data and target values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "models = []\n",
    "models.append(('LogReg', LogisticRegression()))\n",
    "models.append(('XGBoost', XGBClassifier(learning_rate =0.1,n_estimators=100,max_depth=5,min_child_weight=1,gamma=0,subsample=0.8,colsample_bytree=0.8,objective= 'binary:logistic',nthread=4,scale_pos_weight=1,seed=27)))\n",
    "models.append(('LinearSVC',LinearSVC(dual = True,max_iter=1000)))\n",
    "models.append(('MLPClassifier',MLPClassifier(hidden_layer_sizes=(10, ), activation='relu', solver='adam', alpha=0.0001, \n",
    "                                             batch_size='auto', \n",
    "                                             learning_rate='constant', learning_rate_init=0.001)))\n",
    "models.append(('AdaBoost',AdaBoostClassifier(base_estimator=None, n_estimators=50, \n",
    "                                             learning_rate=1.0, random_state=None)))\n",
    "\n",
    "for name, model in models:\n",
    "    print('\\n++++++++++++++ {} ++++++++++++++\\n'.format(name))\n",
    "\n",
    "    # Train model\n",
    "    print('\\n--- Training model using {} ---'.format(name))\n",
    "    model.fit(X_train, y_train)\n",
    "    print('=== DONE ===\\n')\n",
    "    \n",
    "    # Save model\n",
    "    joblib.dump(model, '{}_model_trained.pkl'.format(name))\n",
    "    \n",
    "    # Make predictions on the test-set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Classification report\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print('\\n', report, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. What is the most important inference you can draw from the result? \n",
    "#Modelling\n",
    "After a thorough EDA and preprocessing, data is ready to be fed into a machine learning model. A model also has to be hyper tuned properly for it to produce the best results. Sometimes complicated models are required for a problem but sometimes a simple model does the job for you. Therefore, it has to be seen through experimentation which model work the best. \n",
    "All the hyper-parameter tuning for the below models was done manually because of the computational overheads . Also manual tuning gave more insight on how the model behaved with small changes in the parameters. The code snippets above are only the final stages of the tuning process.\n",
    "\n",
    "#Feature Selection\n",
    "This step allows us to remove features from the dataset which does not provide any value in prediction for a particular model. This in-turn improves the computational speed and can also increase our model performance for different models.Only the features selected from the feature selection process were used for each of the base models. This helped in improving the final score of the model.\n",
    "\n",
    "#Results\n",
    "Out of all the models XGBoost was the best performing one followed by MLP and Adaboost. Thus those two were taken for the final stack. It is a good practice to try simple models first but in this case they didnâ€™t work well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. What is the accuracy score and f1-score for the improved Logistic Regression model? \n",
    "The accuracy score and F-score for logistic model is 63 and 59 which in matrix as above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Why do you think f1-score has improved?\n",
    "Without having access to the dataset, I'm unable to give exact pointers; so I'm suggesting a few directions to approach this problem and help improve the F1 score:\n",
    "\n",
    "Use better features, sometimes a domain expert (specific to the problem you're trying to solve) can give relevant pointers that can result in significant improvements. As , I tried to do some feature engineering .\n",
    "\n",
    "Use a better classification algorithm and better hyper-parameters.\n",
    "\n",
    "#Further to do :SMOTE \n",
    "Over-sample the minority class, and/or under-sample the majority class to reduce the class imbalance.Use higher weights for the minority class, although I've found over-under sampling to be more effective than using weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. For model LinearSVC play with parameters â€“ _dual, max_iter and see if there is any improvement \n",
    "\n",
    "Yes , there is a little bit of change in F1_Score when the max_iter parameter changed from 100 to 100 . And most of the cases LinearSVC needs high number of iterations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. XGBoost is one the better classifiers -- but still f1-score is very low. What could be the reason? \n",
    "\n",
    "It's not exactly low compared to MLP classifier or AdaBoost . The low F1_score may occur when the parameters are not taken properly . I considered the parameters to build the best classifier for XGBoost are:\n",
    "\n",
    "learning_rate =0.1,n_estimators=100,max_depth=5,min_child_weight=1,gamma=0,subsample=0.8,colsample_bytree=0.8,objective= 'binary:logistic',nthread=4,scale_pos_weight=1,seed=27))) . So, it's in tunin the model which gives the goof F1_Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Is there any improvement in scores after encoding? \n",
    "Mostly , No here we can't see improvement in scores after encoding .Because of the noise generated by the variables . Which will have very less existence in the performance of model building."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. If not missing a positive sample is the priority which model is best so far? \n",
    "If targeting a metric score then it's good to be with Boosting algorithms or ensembles. But , when business is concerned XGBoost is less reliable and preference after the target distribution will be taken to SVC or Logisti regression mostly.\n",
    "\n",
    "\n",
    "# 13. If not marking negative sample as positive is top priority, which model is best so far? \n",
    "It's preference is based on the Varaible Importance and the conversions and collinearity in the data . As in the dataset we have faced lot many zeros in the set. So which has no high impact in model building.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. Do you think using AdaBoost can give any significant improvement over XGBoost? \n",
    "No , XG boost works better than adabooost\n",
    "Adaboost and XGBoost are two different ways to derive boosters. Both are generic. I like gradboosting better because it works for generic loss functions, while adaboost is derived mainly for classification with exponential loss. Both of these methods are built based on the idea of converting weak learners to a strong learner by updating based on the residuals (XGBoost) or misclassifications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15. MLPClassifier is the neural network we are trying. But how to choose the right no. of layers and size? \n",
    "The number of hidden neurons should be between the size of the input layer and the size of the output layer. The number of hidden neurons should be 2/3 the size of the input layer, plus the size of the output layer.I considered 10 and 12 as size .But there is no huge difference between the metrics\n",
    "\n",
    "# 16. At what layer size we get the best F1_score\n",
    "\n",
    "Here , it's the 10th layer i got the best f1_Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
